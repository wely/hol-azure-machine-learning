1
# 10. Case Study: Optical character recognition
2
​
3
## 10.1. Overview
4
In this lab, we will develop an end to end solution with cloud backend. This lab is suitable for half day training depending on the level of users' ML knowledge. Based on an OpenSource dataset, we will develope a digit recognition Azure ML solution, publish it as web service, connect with Azure Management API to manage the usage rate, overcome CORS and security issues, and integrate into a simple Azure Web application to draw our own characters on a web page canvas and retrieve the ML prediction about the character. In this lab we will use the [MINST](https://en.wikipedia.org/wiki/MNIST_database), publicly available large database of handwritten digits, to develop our ML model.
5
​
6
We will also give an overview about feature engineering based on this case study. You can find source codes under **appx/odr** folder of this repository.
7
​
8
### 10.1.1. Objectives
9
This lab aims to demonstrate how to develop a simple end to end solution that uses Azure ML solution. Having different type of datasets, we will focus on image understanding and explore the possible feature extraction process.
10
​
11
### 10.1.2. Requirements
12
For better understanding completion of following hands-on-labs recommended:
13
1. Develop and deploy Azure ML web service ([Lab 4.](./004-lab-azureml-experiment.md)).  
14
1. Azure Management API integration ([Lab 9.](./009-lab-monetization.md)).  
15
1. Scripting Python in Azure ML ([Lab 5.](./005-lab-custom-script-r-python.md)).  
16
​
17
## 10.2. Exploring and Understanding the Dataset
18
[MINST](https://en.wikipedia.org/wiki/MNIST_database) handwritten digit images database is also available, ready to use, in Azure ML workspace as one the other sample datasets. Database consists of two dataset, one with 60K records to train an ML module, other is 10K records to test the performance of the developed model. Actually it is a single 70K records dataset, siplit into two. Each record in this database consists of 28 by 28 pixel size digit image data and its corresponding label. 28 width * 28 height = 784 pixels represents the gray scale image capture of a single handwritten digit and an integer type label that represents one of the ten digits (from 0 to 9). So each row in the database consist of 785 columns where the first column is label, the rest 784 columns represent the pixel values of a handwritten digit image. Each pixel value range is from 0 to 255 that corresponds to gray intensity (0 white, 255 black and all inbetween are gray levels). Below image shows first few rows and header of the database table.  
19
​
20
![](./imgs/10.2.i003.jpg)  
21
​
22
First row (exluding the header, column names) of the 10K dataset represents an image of handwritten digit 7. If we convert this row data into an black-white (all pixel values >0 is converted to 255) image representation, it will look like:  
23
![](./imgs/10.2.i002.jpg)  
24
​
25
How we represent a one dimensional single row of data with 784 columns as 28 by 28 pixel size two dimensional image? Reshaping these 784 columns as 28 rows per line, we will get 28x28 pixel image (28 by 28 matrix).  
26
![](./imgs/10.2.i004.jpg)  
27
​
28
which is in numerical representation:  
29
![](./imgs/10.2.i001.jpg)  
30
​
31
### 10.2.1. Process MINST database in Azure ML with Python script
32
1. Open [Azure Machine Learning Studio](http://studio.azureml.net).  
33
​
34
1. Create a blank Azure Machine learning experiment.  
